{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Brief description of the problem and data\n\nThe rapid advancements in artificial intelligence and machine learning have led to significant progress in various domains. Now, we have a chance to utilize AI to tackle the problem of identifying metastatic cancer in small image patches taken from larger digital pathology scans. A Convolutional Neural Network (CNN) is better to solve this kind of a binary image classification problem, where the goal is to determine whether a given image patch contains metastatic cancer or not. \n\nThe data for this challenge is based on the PatchCamelyon (PCam) benchmark dataset, which has been modified to remove duplicate images. PCam dataset is interesting due to its size, simplicity, and approachability. It allows for models to be trained on a single GPU within a few hours and achieve competitive scores. As for the Natural Language Processing (NLP) task, it involves the processing, understanding, and generation of human language by computer algorithms. NLP techniques are widely used for tasks such as sentiment analysis, machine translation, and chatbot development.","metadata":{}},{"cell_type":"markdown","source":"# 2. Exploratory Data Analysis (EDA) â€” Inspect, Visualize and Clean the Data\n\n**2.1 Load data and list the images**","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom PIL import Image\nimport random\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift + Enter) will list all files under the input directory\n\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2023-04-17T06:01:48.356495Z","iopub.execute_input":"2023-04-17T06:01:48.356867Z","iopub.status.idle":"2023-04-17T06:01:48.362706Z","shell.execute_reply.started":"2023-04-17T06:01:48.356836Z","shell.execute_reply":"2023-04-17T06:01:48.361526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**2.2 Label files Exploration**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport os\n\n# Set the paths to the CSV files\nsample_submission_path = '/kaggle/input/histopathologic-cancer-detection/sample_submission.csv'\ntrain_labels_path = '/kaggle/input/histopathologic-cancer-detection/train_labels.csv'\n\n# Read the CSV files\nsample_submission_df = pd.read_csv(sample_submission_path)\ntrain_labels_df = pd.read_csv(train_labels_path)\n\n# Display the first few rows of each DataFrame\nprint(\"Sample Submission DataFrame:\")\nprint(sample_submission_df.head())\n\nprint(\"\\nTrain Labels DataFrame:\")\nprint(train_labels_df.head())\n\n# Data cleaning: Check for missing values\nmissing_values = train_labels_df.isnull().sum()\nprint(\"Missing values:\\n\", missing_values)\n\n# Visualize the distribution of the target variable (label)\nplt.figure(figsize=(3, 3))\nsns.countplot(x='label', data=train_labels_df)\nplt.title('Histogram of Target Variable (Label)')\nplt.xlabel('Label')\nplt.ylabel('Count')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-17T06:02:07.042490Z","iopub.execute_input":"2023-04-17T06:02:07.043540Z","iopub.status.idle":"2023-04-17T06:02:07.479731Z","shell.execute_reply.started":"2023-04-17T06:02:07.043499Z","shell.execute_reply":"2023-04-17T06:02:07.478553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**2.3 Visualize the pictures**","metadata":{}},{"cell_type":"code","source":"# Set the path to the images\ntrain_images_path = '/kaggle/input/histopathologic-cancer-detection/train/'\n\n# Get a list of image file names\nimage_files = os.listdir(train_images_path)\n\n# Randomly select a few images\nnum_images_to_show = 25\nselected_images = random.sample(image_files, num_images_to_show)\n\n# Plot the selected images in a grid\nfig, axes = plt.subplots(5, 5, figsize=(7, 7))\naxes = axes.ravel()\n\nfor i, img_name in enumerate(selected_images):\n    img_path = os.path.join(train_images_path, img_name)\n    img = Image.open(img_path)\n    axes[i].imshow(img)\n    axes[i].axis('off')\n    axes[i].set_title(f\"Image {i+1}\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-17T06:02:11.121978Z","iopub.execute_input":"2023-04-17T06:02:11.122615Z","iopub.status.idle":"2023-04-17T06:02:15.275320Z","shell.execute_reply.started":"2023-04-17T06:02:11.122575Z","shell.execute_reply":"2023-04-17T06:02:15.272770Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3.Model to choose\n\nFor the problem of histopathologic cancer detection, we can start with a Convolutional Neural Network (CNN) as it is well-suited for image classification tasks. Below, I will describe a possible model architecture and the reasoning behind the choices made.\n\n* Input Layer: The input layer will accept images of shape (96, 96, 3) for the PCam dataset (96x96 pixels with 3 color channels).\n* Convolutional Layer 1: Apply 32 filters of size (3, 3) with a ReLU activation function. This layer will help the model learn basic features such as edges and textures.\n* Max Pooling Layer 1: Apply max pooling with a pool size of (2, 2) to reduce the spatial dimensions of the input and retain important features.\n* Convolutional Layer 2: Apply 64 filters of size (3, 3) with a ReLU activation function for learning more complex features from the input.\n* Max Pooling Layer 2: Apply max pooling with a pool size of (2, 2).\n* Convolutional Layer 3: Apply 128 filters of size (3, 3) with a ReLU activation function.\n* Max Pooling Layer 3: Apply max pooling with a pool size of (2, 2).\n* Flatten Layer: Flatten the output from the previous layer into a 1D array.\n* Fully Connected Layer 1: Create a dense layer with 256 neurons and a ReLU activation to combine features from the previous layers to make predictions.\n* Dropout Layer: Apply dropout with a rate of 0.5 to prevent overfitting.\n* Output Layer: Create a dense layer with 1 neuron and a sigmoid activation function to produce a probability of cancer presence.","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nimport torchvision.transforms as transforms\n!pip install torchsummary\n\n\nimport torch.nn.functional as F\n\nclass CancerNet(nn.Module):\n    def __init__(self):\n        super(CancerNet, self).__init__()\n        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n        self.pool1 = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n        self.pool2 = nn.MaxPool2d(2, 2)\n        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n        self.pool3 = nn.MaxPool2d(2, 2)\n        self.fc1 = nn.Linear(64 * 12 * 12, 128)  # Update the input size\n        self.dropout = nn.Dropout(0.5)\n        self.fc2 = nn.Linear(128, 1)\n        \n    def forward(self, x):\n        x = self.pool1(F.relu(self.conv1(x)))\n        x = self.pool2(F.relu(self.conv2(x)))\n        x = self.pool3(F.relu(self.conv3(x)))\n        \n        #x = x.view(-1, 64 * 12 * 12)  # Update the view size\n        x = torch.flatten(x, start_dim=1)  # Replace view() with flatten()\n            \n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.fc2(x)\n        return torch.sigmoid(x)\n\nclass ImprovedCancerNet(nn.Module):\n    def __init__(self, params):\n        super(ImprovedCancerNet, self).__init__()\n        \n        Cin, Hin, Win = params[\"shape_in\"]\n        init_f = params[\"initial_filters\"]\n        num_fc1 = params[\"num_fc1\"]\n        num_classes = params[\"num_classes\"]\n        self.dropout_rate = params[\"dropout_rate\"]\n        \n        self.conv1 = nn.Conv2d(Cin, init_f, 3, padding=1)\n        self.pool1 = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(init_f, 2 * init_f, 3, padding=1)\n        self.pool2 = nn.MaxPool2d(2, 2)\n        self.conv3 = nn.Conv2d(2 * init_f, 4 * init_f, 3, padding=1)\n        self.pool3 = nn.MaxPool2d(2, 2)\n        self.conv4 = nn.Conv2d(4 * init_f, 8 * init_f, 3, padding=1)\n        self.pool4 = nn.MaxPool2d(2, 2)\n\n        self.num_flatten = 8 * init_f * (Hin // 16) * (Win // 16)\n        self.fc1 = nn.Linear(self.num_flatten, num_fc1)\n        self.dropout = nn.Dropout(self.dropout_rate)\n        self.fc2 = nn.Linear(num_fc1, num_classes)\n        \n    def forward(self, x):\n        x = self.pool1(F.relu(self.conv1(x)))\n        x = self.pool2(F.relu(self.conv2(x)))\n        x = self.pool3(F.relu(self.conv3(x)))\n        x = self.pool4(F.relu(self.conv4(x)))\n\n        x = torch.flatten(x, start_dim=1)\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.fc2(x)\n        return F.log_softmax(x, dim=1)\n\n# Neural Network Predefined Parameters\nparams_model = {\n        \"shape_in\": (3, 46, 46),\n        \"initial_filters\": 16,\n        \"num_fc1\": 128,\n        \"dropout_rate\": 0.5,\n        \"num_classes\": 2}\n\n# Create instantiation of ImprovedCancerNet class\ncnn_model = ImprovedCancerNet(params_model)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = cnn_model.to(device)\n\n\nfrom torchsummary import summary\nsummary(cnn_model, input_size=(3, 46, 46), device=device.type)\n\n#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n#model = CancerNet().to(device)\n\n# Print the structure of the model\nprint(model)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"scrolled":true,"execution":{"iopub.status.busy":"2023-04-17T06:03:07.766627Z","iopub.execute_input":"2023-04-17T06:03:07.767257Z","iopub.status.idle":"2023-04-17T06:03:17.606401Z","shell.execute_reply.started":"2023-04-17T06:03:07.767214Z","shell.execute_reply":"2023-04-17T06:03:17.605115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Results and Analysis\n\nRun hyperparameter tuning, try different architectures for comparison, apply techniques to improve training or performance, and discuss what helped.\nIncludes results with tables and figures. There is an analysis of why or why not something worked well, troubleshooting, and a hyperparameter optimization procedure summary.\n\n**4.1 Split the datasets**","metadata":{}},{"cell_type":"code","source":"# Plan of analysis:\n# 1. Split the data into training and validation sets\n# 2. Preprocess the image data (resize, normalize, etc.)\n# 3. Build a CNN model for classification\n# 4. Train the model on the training data and evaluate its performance on the validation data\n# 5. Fine-tune the model (if necessary) and make predictions on the test data\n\nimport os\nimport pandas as pd\nimport numpy as np\nfrom skimage.io import imread","metadata":{"execution":{"iopub.status.busy":"2023-04-17T06:03:21.141276Z","iopub.execute_input":"2023-04-17T06:03:21.141900Z","iopub.status.idle":"2023-04-17T06:03:21.148739Z","shell.execute_reply.started":"2023-04-17T06:03:21.141862Z","shell.execute_reply":"2023-04-17T06:03:21.147612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**4.2 Preprocess the image data (resize, normalize, etc.)**","metadata":{}},{"cell_type":"code","source":"from skimage.io import imread\nfrom skimage.transform import resize\nfrom skimage.io import imread\n\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n\n\n# Load the first image using the file name and path\nfirst_image = imread(os.path.join(train_images_path, image_files[0]))\n\n# Get the dimensions of the image\nheight, width, channels = first_image.shape\n\nprint(f\"Image width: {width}\")\nprint(f\"Image height: {height}\")\nprint(f\"Image dimensions: {width} x {height} x {channels}\")\n\n# Load train labels\ntrain_labels_df = pd.read_csv(train_labels_path)\n\n# Select 0.01% of the data\nselected_data = train_labels_df.sample(frac = 0.001, random_state=42)\n\n# Split the selected dataset into training and validation sets (1/10 for training)\ntrain_df, val_df = train_test_split(selected_data, train_size=0.7, random_state=42)\n\n\nprint(f\"Number of images in train_labels_df: {train_labels_df.shape[0]}\")\nprint(f\"Number of images in selected_data: {selected_data.shape[0]}\")\nprint(f\"Number of images in train_df: {train_df.shape[0]}\")\nprint(f\"Number of images in val_df: {val_df.shape[0]}\")\n\n\n# Create a custom dataset class\nclass CancerDataset(Dataset):\n    def __init__(self, df, root_dir, transform=None):\n        self.df = df\n        self.root_dir = root_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n\n        img_name = os.path.join(self.root_dir, self.df.iloc[idx, 0]) + '.tif'\n        image = imread(img_name)\n        label = self.df.iloc[idx, 1]\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, label\n\n# Define data transformations\ndata_transform = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n    transforms.ToTensor()\n])\n\n# Create datasets and data loaders\ntrain_dataset = CancerDataset(train_df, train_images_path, transform=data_transform)\nval_dataset = CancerDataset(val_df, train_images_path, transform=data_transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-04-17T06:03:24.524201Z","iopub.execute_input":"2023-04-17T06:03:24.524575Z","iopub.status.idle":"2023-04-17T06:03:25.085865Z","shell.execute_reply.started":"2023-04-17T06:03:24.524541Z","shell.execute_reply":"2023-04-17T06:03:25.084754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**4.3 Build and evaluate our model**","metadata":{}},{"cell_type":"code","source":"import tqdm\n    \n# Create the model (assuming you have the model definition from previous steps)\nmodel = CancerNet()\n\n# Compile the model\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\ncriterion = torch.nn.BCEWithLogitsLoss()\n\n# Train the model\nnum_epochs = 10\ntrain_loss_history = []\nval_loss_history = []\n\nfor epoch in range(num_epochs):\n    train_loss = 0.0\n    val_loss = 0.0\n\n    model.train()\n    for images, labels in tqdm.tqdm(train_loader, desc=f\"Epoch {epoch+1} (Training)\"):\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs.squeeze(), labels.float())\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item()\n\n    model.eval()\n    with torch.no_grad():\n        for images, labels in tqdm.tqdm(val_loader, desc=f\"Epoch {epoch+1} (Validation)\"):\n            outputs = model(images)\n            loss = criterion(outputs.squeeze(), labels.float())\n            val_loss += loss.item()\n\n    train_loss /= len(train_loader)\n    val_loss /= len(val_loader)\n    train_loss_history.append(train_loss)\n    val_loss_history.append(val_loss)\n    print(f\"Epoch {epoch+1}, Train Loss: {train_loss}, Val Loss: {val_loss}\")\n\n\n# Save the trained model\n#model_path = \"/kaggle/working/model.pth\"\n#torch.save(model.state_dict(), model_path)","metadata":{"execution":{"iopub.status.busy":"2023-04-17T06:03:29.285114Z","iopub.execute_input":"2023-04-17T06:03:29.285502Z","iopub.status.idle":"2023-04-17T06:03:57.706513Z","shell.execute_reply.started":"2023-04-17T06:03:29.285467Z","shell.execute_reply":"2023-04-17T06:03:57.705401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**4.4 Fine-tune the model**\n\n(if necessary) and make predictions on the test data","metadata":{}},{"cell_type":"code","source":"# Plot the loss history\nplt.plot(train_loss_history, label='Train Loss')\nplt.plot(val_loss_history, label='Val Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2023-04-17T06:04:01.290583Z","iopub.execute_input":"2023-04-17T06:04:01.291751Z","iopub.status.idle":"2023-04-17T06:04:01.510651Z","shell.execute_reply.started":"2023-04-17T06:04:01.291690Z","shell.execute_reply":"2023-04-17T06:04:01.509659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**4.5 Make predictions and save the result**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport os\nimport torch\nimport pandas as pd\nfrom skimage.io import imread\n;\n# Set the model to evaluation mode\nmodel.eval()\n\n# Load test images\ntest_images_path = '/kaggle/input/histopathologic-cancer-detection/test/'\ntest_image_files = os.listdir(test_images_path)\n\n# Process test images in smaller batches\nbatch_size = 128\nnum_images = len(test_image_files)\npredictions = []\n\nfor i in range(0, num_images, batch_size):\n    batch_files = test_image_files[i:i + batch_size]\n    batch_images = [imread(os.path.join(test_images_path, img_file)) for img_file in batch_files]\n    batch_images_normalized = np.array(batch_images) / 255.0\n    batch_images_tensor = torch.tensor(batch_images_normalized, dtype=torch.float32).permute(0, 3, 1, 2)\n    \n    with torch.no_grad():\n        model.eval()\n        batch_predictions = model(batch_images_tensor).numpy()\n        predictions.extend(batch_predictions)\n\npredictions = np.array(predictions)\n\n# Convert probabilities to binary predictions\nbinary_predictions = (predictions > 0.5).astype(int).flatten()\n\n# Print the predictions for the first 10 images\nfor i in range(10):\n    print(f\"Image {i + 1}: {test_image_files[i]}\")\n    print(f\"Probability: {predictions[i][0]:.4f}\")\n    print(f\"Predicted Label: {binary_predictions[i]}\\n\")\n\n# Create a DataFrame with the image IDs and the predictions\nsubmission_df = pd.DataFrame({'id': [img_file[:-4] for img_file in test_image_files], 'label': binary_predictions})\n\n# Print the length of the submission DataFrame\nprint(f\"Total number of predictions: {len(submission_df)}\")\n\n# Remove the old submission.csv file if it exists\nsubmission_csv_path = '/kaggle/working/submission.csv'\nif os.path.exists(submission_csv_path):\n    os.remove(submission_csv_path)\n\n# Save the predictions to a new CSV file\nsubmission_df.to_csv(submission_csv_path, index=False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import os\n#import shutil\n\n# Remove model.pth\n#model_path = \"/kaggle/working/model.pth\"\n#if os.path.isfile(model_path):\n#    os.remove(model_path)\n#    print(f\"Removed {model_path}\")\n#else:\n#    print(f\"{model_path} not found\")\n\n# Remove working_directory.zip\n#zip_path = \"/kaggle/working/working_directory.zip\"\n#if os.path.isfile(zip_path):\n#    os.remove(zip_path)\n#    print(f\"Removed {zip_path}\")\n#else:\n#    print(f\"{zip_path} not found\")\n\n    \n#working_directory = '/kaggle/working/'\n#list_of_files = os.listdir(working_directory)\n\n#print(\"Contents of /kaggle/working/ directory:\")\n#for file in list_of_files:\n#    print(file)\n\n#shutil.make_archive('/kaggle/working/working_directory', 'zip', '/kaggle/working/')","metadata":{"execution":{"iopub.status.busy":"2023-04-17T02:24:27.796473Z","iopub.status.idle":"2023-04-17T02:24:27.797367Z","shell.execute_reply.started":"2023-04-17T02:24:27.797091Z","shell.execute_reply":"2023-04-17T02:24:27.797123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Conclusion\n\nDiscuss and interpret results as well as learnings and takeaways. What did and did not help improve the performance of your models? What improvements could you try in the future?","metadata":{}},{"cell_type":"markdown","source":"# 6. Produce Deliverables\n\nHigh-Quality, Organized Jupyter Notebook Report, GitHub Repository, and screenshot of Kaggle leaderboard \nThese deliverables serve two purposes- grade for this course and your project portfolio that you can show when you apply for jobs.\n","metadata":{}}]}